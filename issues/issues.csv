Id, Title, Creator, Assignee, Milestone, State, Body Text
57,Воображаемые миры,Nashev,null, ,OPEN,Слово воображаемые в этом тексте возможно стоит заменить на конструируемые, с учетом того, что хранить и генерировать их могут не только мозги с воображением, но и компьютер с алгоритмами.

Ещё правильнее говорить о представлении о мире. Реальном, воображаемом, возможном. Да и не о мире только, ещё и об обстоятельствах, предметах, о чём угодно. Представления требуют проверки непротиворечивости, для этого нужна логика, модальная логика и т.п. Представления о реальности должны сверяться с сенсорным потоком, о литературном мире - с первоисточником. Тут возникает вопрос о самом мире, о любом предмете представления, существует ли он - но этот вопрос не важен, вроде бы. Почему то... Важно наличие и надежность источника представлений. Его стабильность. Их закономерность.

Мы напрямую имеем дело со своими воображаемыми мирами, через средства передачи (общение, чтение, наблюдение, пантомиму, балет и т.п.) - с чужими воображаемым мирами, и с одним общим реальным миром имеем дело косвенно, через его влияние на нас и наши органы чувств.  То, что воображаемые миры - это дело мозгов воображающего, делает их эпистемическими. Это же делает их такими же реальными объектами реального мира, какими являются мысли, умозрительные конструкции и представления индивидов.

Воображаемые миры можно поделить на являющиеся представлением о реальном мире и вымышленные. И те, и другие, могут быть гипотезами, прогнозами и представленями о будущем, настоящем и прошлом. Гипотез может быть одновременно много, каждая со своей оценкой достоверности (объективности), зависящей от различных известных и неизвестных условий (задаются контрфактически, являются модальными). В связи с тем, что воображаемые миры часто задаются функционально, они часто даже не формируются полностью. Могут содержать сколь угодно незамеченных внутренних противоречий, могут представлять собой целый ворох (или веер, или даже непрерывной спектр) возможных вариантов сразу, со спектром оценок достоверности и т.п.  Подсчёту (квантификаци?) поддаются не всегда. Самый яркий пример - представления о реальном мире. Часто противоречивые, неполные, полные заблуждений. Вся наука, собственно, тем и занимается, что пытается их дополнить и подчистить, но часто замусоривает новым шлаком. 
Накидать примеров миров. Вселенная звездных войн, мир Толкиена, последствия выбора, альтернативная история... 
Название "Возможные" - это слишком узко.

Задача поиска реальных истин сводится к поиску и выбору того подмножества из воображаемых миров, которое наиболее релевантно реальности. Воображаемые миры, в достаточной степени релевантные реальности могут называться возможными мирами. Уточнение спектра возможных миров производится путем добавления к рассмотрению сенсорных фактов и путем поиска и исключения вариантов с противоречиями. Процедура доказательства гипотезы становится демонстраций отсутствия противоречий с сенсорным потоком. Сенсорный поток - это всё, что мы имеем из реального мира. Можно верить в солипсизм и тогда вся наука о реальном мире - это лишь изучение закономерностей строения сенсорного потока.  Отделение области возможного от области действительно реального (Модальная логика, Р. Фейс, 04.2) невозможно в принципе!

Представления об объектах этих миров соответствуют мнению коннекционистов (и нейрофизиологов): каждый воображаемый объект в воображаемых мирах представлен лишь множеством ассоциаций с известными субъекту ощущениями (sense-data - следами восприятия), и следующими из них умозаключениями всех порядков (результатами распознавания первичных признаков, узнавания, абстрагирования,  что реконструкции, прогнозирования и т.п.) то есть субъективно интенсиональны, и являются экспликацией пропозициональных установок индивида, указываются перцептуально (и это то же самое, что и дискриптивно (!), вопреки утверждению на стр. 51). Набор ассоциаций можно назвать "Интенсиональная индивидуализирующая функция", если говорить о нём как о способе идентифицировать один и тот же объект в разных воображаемых мирах. Одному объекту может соответствовать множество функций, и одной функции - множество объектов, множество разное в разных мирах. Ассоциации в голове складываются вовсе не только между словами какого-либо языка, так что о языковой спецификации мира и объектов говорить не приходится. Хотя, часто всё же можно рассматривать подмножество, выражаемое языком. Воображаемые миры референтативно не ясны (не прозрачны, не однозначны, множественны) в общем случае. Оперируя совокупностями ассоциаций, подразумеваем объекты, но фактически самими объектами никогда не оперируем.

Статистическая основа наборов ассоциаций о реальном мире: мы запоминаем, как люди говорят, то есть какие слова и словосочетания в каких ситуациях используют. Если что не так - мы скажем "но так же не говорят!" Весь язык построен на этом, на статистике. "Так говорят, так склоняют, так спрягают, так называют. Это при мне назвали так. Это не склоняют. Про это говорят, про это не говорят. Возмущаются так, удивляются так, просят так, смеются так, звуки произносят так." Всё статистика! Да, бывают разовые наблюдения, они тоже запоминаются. Многократные - суммируются. (связать с мирами). Статистика контекстно-зависимая: "тут так не принято, тут говорят так. Когда про то говорим - значит, термин значит вон тот смысл, иначе - тоже по обстоятельствам." Все смыслы соотносятся с конкретными контекстами: мирами и обстоятельствами в них.

Миры как контекст высказывания.

Вот тут тонкий момент, надо его подумать: контексты разговоров не всегда миры, иногда просто темы, обстоятельства в этом мире. Можно ли считать выбор темы выбором воображаемого мира? Или не стоит ли вместо воображаемого мира говорить сразу о теме, контексте или ещё чём-то таком?.. Или мир - частный случай контекста, и можно перечислить остальные частные случаи? Или миры тоже контекстно-зависимы, и влияют на семантику знаков наравне с остальным контекстом, являются его частью, а не видом?.. Нет. Мир большой, в нём возможны разные обстоятельства, и контекст - это как раз мир и обстоятельства в нём. Или, точнее, не сами они, а то, что о них известно. Спектр миров и обстоятельств, подходящих под известные уточнения. Или, что почти то же самое, сам набор уточнений и все возможные его следствия. Кажется, не получается считать обстоятельства недоопределённым микромиром. А может можно считать миры макрообстоятельствами?.. Типа, миров нет, есть лишь разной полноты и обособленности наборы обстоятельств. Хотя, если говорить на тему мира, то значит есть и сам мир... как один из типичных видов наборов.

Таким образом, "проблема прослеживания индивидуумов сквозь возможные миры" вырождается в проблему сравнения наборов ассоциаций и оценки возможности распространения набора ассоциаций на интересующие воображаемые миры. И то и другое может быть весьма нечётким и оценочным, и неизбежно порождает многочисленные ошибки, особенно явные, когда речь идёт о мирах, являющихся представленями индивида о временных срезах реального мира: легко как не узнать старого знакомого, так и опознаться...

Фундаментальные логические законы типа подставимости тождественного или экзестенциального обобщения - тоже частные случаи сравнения множеств ассоциаций. Подставимы тождественные подмножества свойств и обстоятельств.

Примеры задач и их решений в условиях воображаемых миров нужны очень. Формальная запись условий, законов и решений. Переформулировка и переосмысление законов логики, исчисление предикатов и т.п.

Миры тоже состоят из фактов (ассоциаций) про объекты в них.

Свойства и обстоятельства - разные виды ассоциаций. Чем разные?

Мировые ленты и деревья, а не линии.

Миры большие (известная индивиду реальность, или вселенная звездных войн) и маленькие (определенные малым количеством фактов). Миры самостоятельные или относительные, то есть как вон тот, но отличающийся тем-то). По умолчанию - относительные, то есть к ним применимо всё известное о реальном мире, кроме явно отрицаемого, плюс явно добавленное. Как правило, опираются на представление о реальном мире или на представление о предыдущих состояниях того же воображаемого.

Миры и время: воображаемый мир - это скорее статический момент, конкретное состояние, включающее известную предысторию. Будущее в них часто неоднозначно, поэтому в будущем любого воображаемого мира практически всегда целый спектр возможных миров, активно ветвящийся. Дерево. Хотя, это не обязательно, ибо можно вообразить мир,будущее которого чётко предопределено... Хотя, говоря про всё дерево состояний мира, мы миром называем всю совокупность состояний, всё дерево.. Будущее мира часто многовариантно, и каждый вариант - такой же мир.

Миры типа реальности и миры абстракций типа математических или мир объектов компьютерной программы. Миры разной детализации (подробные или поверхностные, абстрактные, модельные)

Онтология данных утверждений состоит из наличия ощущений разных уровней, ассоциаций между ними и возможностью их собирать в наборы (множества) и складывать/пересекать такие наборы друг с другом в полном, мне кажется, согласии с теорией множеств.

Миры, сформированные воображением писателя и выраженные письменным языком, состоят из набора утверждений о них. Опираются на реальный мир в остальном - во всём, что не оговорено их автором. Содержат описанные автором объекты, существующие в реальном мире лишь в виде совокупности авторских описаний так же, как и сами эти миры, но вполне полноценно существующие в своих мирах.

Всё это написано по мере чтения книжки "Философские проблемы семантики возможных миров", Целищев В. В., изд.  Краснад", Москва, 2009 г. http://urss.ru, в которой автор описывает заочный спор Хинтикки с Куайном, и добавляет соображений от себя.

На 46 странице в примере - подмена понятий. Возможный мир это не реальный мир. Ни один. Объекты возможных миров - это не индивидуирующие их функции.,
56,Исходные тексты,Nashev, , ,OPEN,Это тоже элементы знания, видимо. При хранении на диске базы знаний #6 их можно тож забирать себе в базу, в папку элементов такого вот типа, "исходный текст"

Для элементов типа HTML-страницы из интернета тож можно их копии утягивать себе в такую папку, но не забывать исходный адрес (например, чтоб при необходимости можно было почистить эту папку утянутого, и потом при повторной необходимости утягивать всё заново).

Элементы знания, говорящие о привязке конкретного слова к конкретному месту в тексте, наверное могут быть виртуальными, и реконструироваться по тексту каждый раз когда вдруг нужны, в памяти? Или их многовато для большого текста? Как их адресовать? Как они живут, если текст меняется - редактируется пользователем или при обновлении с веб-адреса оказывается изменённым?..,
55,Мобильные версии чего-нибудь для чего-нибудь,Nashev, , ,OPEN,Как одно из возможных решений #54,
54,Монетизацию придумать и сделать,Nashev, , ,OPEN,,
53,RDF vs Виды элементов знаний,Nashev,null, ,OPEN,В затее #9 выписываются элементы знания. В #32 описываются отдельные сети/базы знаний. В #6 описывается, как их хранить на диске.

Надо б понять, как всё это соотносится с идеями RDF, с их триплетами и с их пространствами имён.,
52,Браузер знаний локальный ("инспектор объектов"),Nashev, , ,OPEN,В дополнение к #15 и #16 хочется что-то вроде инспектора объектов иметь, чтоб любой элемент знаний можно было прям на месте посмотреть - его причины, следствия и прочее, что у него есть, и если надо - перейти на них.

Как сейчас, встав на TSimpleTextFileSourceItem я вижу его источник в исходном тексте (#14), так встав на любой другой элемент знания, я хочу видеть всё про него.,
51,Анализ тональности,Nashev, , ,OPEN,http://habrahabr.ru/post/149605/
пересекается с #46,
50,Умная записная книжка,Nashev, , ,OPEN,Ты в неё вписываешь очередные свои утверждения, планы, подходы - а она их интегрирует в ранее записанное, сверяет, выявляет противоречия и следствия, и всё это предъявляет автору. ,
49,визуализация формирования текста,Nashev, , ,OPEN,сверху сформированный текст, под ним облако связанных ниточками с последними его словами смыслов и их следствий на пару- тройку шагов вперед (с регулятором), тающее в тумане отдаленных следствий. Смыслы в облаке представлены цветными точками и подписями к ним, возможно всплывающими, и связаны такими же ниточками друг с другом. Можно выбрать смысл, который уложится в текст следующим. Можно добавлять правила для автоматического выбора. ,
48,Синонимы, синсеты,Nashev, , ,OPEN,Факт о том, что слова значат одно и то же, но это разные слова (отличать этот факт от форм слова и их связи с основной формой слова #47).

Возможно, получать из словарей типа WordNet.
Возможно, как-то статистически - типа, у этих слов связи с одним и тем же облаком свойств или объектов (#10).
Возможно, выявлять из предложений самого текста, утверждающих о синонимичности - типа "XXX это YYY"
Возможно, указывать вручную - типа, вот это и это слово считать синонимами.

Виды синонимии: различать/преобразовывать отношения "тождественно равно" в отношения класс-экземпляр, множество-подмножество (класс-подкласс), в этой теме/тексте или вообще всегда и т.д.

Возможно, тут правильнее вообще работать на уровне понятий, объектов (см. RDF, #42), а не слов.,
47,Основная форма слова (лемма) - морфология,Nashev, , ,OPEN,"[Лемма](https://ru.wikipedia.org/wiki/%D0%9B%D0%B5%D0%BC%D0%BC%D0%B0_(%D0%B7%D0%BD%D0%B0%D1%87%D0%B5%D0%BD%D0%B8%D1%8F))" (морфология) или "[стемма](https://ru.wikipedia.org/wiki/%D1%F2%E5%EC%EC%E8%ED%E3)" (обрезание), или ещё что-то. Результат или основа морфологического анализа, возможно результат статистического анализа или использования словаря типа WordNet.,
46,Distant reading,Nashev, , ,OPEN,Обеспечить возможность показать обзор понятий и структуры текста - о чем речь, в каком порядке какие факты подаются, где сколько американской хвалебной воды и завтраков...,
45,Облачные вычисления,Nashev, , ,OPEN,Параллелить вычисления, хранение, и выносить все это в облака,
44,История изменений по мере анализа лексем,Nashev, , ,OPEN,Историю изменений текущего контекста этого "текстового мозга" хранить в виде "ключевых кадров" и цепочки "диффов" между ними. Любой ключевой кадр (кроме стартового) должно быть можно реконструировать в любой момент по предыдущему и дифам. И так же дропнуть.

Кадр - это состояние "ума" по мере чтения текста, текущий контекст, текущий набор мнений об описываемой ситуации с оценкой уверенности в них, от убеждений до сомнительных гипотез (прогнозы следствий, варианты интерпретации).,
43,угадывалка,Nashev, , ,OPEN,Сделать игрушку, которая будет угадывать задуманный пользователем концепт, задавая ему вопросы про свойства задуманного, выбирая их из онтологии. Возможно, как простенький Веб-сервис, генерирующий SPARQL-запросы к общедоступным семантическим сетям. ,
42,Использовать Корпуса текстов и Semantic WEB. Позиционироваться как NLP,Nashev, , ,OPEN,http://cleverdon.hum.uva.nl/marijn/ESSLLI2014/CLforDH_day4_slides.html
http://www.nltk.org/
http://esslli2014.info/wiki/corpus-linguistics-for-digital-humanities/ (EsslliTuebingen),
41,визуализации,Nashev, , ,OPEN,http://vcg.informatik.uni-rostock.de/~hs162/treeposter/poster.html - варианты визуализации деревьев
http://habrahabr.ru/post/231757/ про редакторы структурированных данных,
40,похожие запросы,Nashev,null, ,OPEN,http://habrahabr.ru/company/hh/blog/231393/
"У большинства крупных поисковиков и сервисов есть механизм похожих поисковых запросов, когда пользователю предлагаются варианты, тематически близкие к тому, что он искал. Так делают в google, yandex, bing, amazon, несколько дней назад это появилось и у нас на hh.ru!",
39,Использовать www.transifex.com для поддержки локализаций,Nashev, , ,OPEN,в дополнение к #17 - https://www.transifex.com/projects/p/textbrain/,
38,Саккады, видео картинки на сетчатке ,Nashev, , ,OPEN,Найти или изобразить, что именно видит сетчатка, с точки зрения сетчатки - на основании трекинга движения глаз и чувствительности разных её частей, включая слепое пятно. Интересное видео должно быть)

Машинное зрение на основании реальной записи трекинга глаз изобразить так, чтобы алгоритму саккады помогали, а не мешали... ,
37,Время в пространство, и далее анализ пространства и пространства,Nashev,null, ,OPEN,Нейроны работают с пространствеными паттернами, меняющимися во времени. Но сравнивать они могут лишь одновременные состояния нейронов. Сравнение с ранее имевшимися картинами возможно лишь на базе линий задержки, когда соседний нейрон показывает то состояние, которое было у текущего нейрона мгновение назад.

Линия задержки похожа на сдвиговый регистр, преобразующий последовательную цепочку активности в ряд одновременно присутствующих активностей нейронов. Далее, глядя на всю получившуюся развертку сигнала во времени, можно распознать в этой картине что-то, можно параллельным переносом скопировать в память целиком, можно ранее скопированное таким образом загнать и воспроизвести последовательно...

Воспроизводить ранее известное в новых контекстах, сравнивать входящий поток с предсказаниями, замечать отличия. 

Распознаватели показывают что на входе, память показывает что вспоминает, сравниватели сравнивают и сигнализируют. Вернее, память подогревает подпороговой активностью что-то, что промолчит, если на входе будет то что надо, или возвопит о новизне, если будет что-то иное. То, что нужно обдумать сильнее и возможно запомнить. Если предсказание подтвердится, то предсказанное запоминается сильнее, легче вспомнится... 

Предсказанное легче распознается. Оно подогрето, оно готово быть распознанным. 

Воспроизводить временную цепочку по пространственной записи

Младенец, двигая руками и игрушками в поле зрения, синхронизирует моторику рук и глаз со зрением. Погремушки - ещё и со слухом. 

Слова, стоящие рядом со словом "это" ассоциирутся с ним и друг с другом. В детстве такие фразы ребёнок слышит часто. В итоге они начинают и друг с другом ассоциироваться, наверное. 

Все это записано при чтении книжки ["Об интеллекте", Джефф Хокинс](http://dmitry.bancorp.ru/Hawkins/On_Intelligence_Rus.doc) (см. так же http://littlemess.narod.ru/index/0-2 и http://numenta.com/htm-overview/education/HTM_CorticalLearningAlgorithms_ru.pdf),
36,Автоассоциативность ,Nashev,null, ,OPEN,Частное должно активировать общее, целое должно находиться (активироваться) по отдельным деталям. Это значит, что должен быть активный набор и он должен пополняться по ассоциациям, и применяться для работы детекторов и вывода на экран. Фокус внимания,
35,Два интерфейса - полный и кнопка "сделайте мне красиво",Nashev,null, ,OPEN,http://habrahabr.ru/company/maxifier/blog/191922/ :

"А не повезло потому, что в тот момент, не имея достаточного опыта на этом рынке, мы стали разрабатывать продукт, предполагая, что все игроки такие же умные, как эти ребята из MediaRun. Поэтому первая версия интерфейса по сложности очень напоминала приборную панель самолета.

Мы создали очень сложную систему интеллектуальной поддержки принятия решений, с режимом обучения, огромным количеством опций и конфигураций, возможностей подстройки под себя и прочее, прочее, прочее. А затем, все последующие годы, вынуждены были все упрощать, скрывать и минимизировать. Ибо, как выяснилось, мечта обычного клиента – одна кнопка «Сделай мне хорошо». Ну и плюс, система отчетов для начальства вида «У меня все под контролем».",
34,Корпус текстов русского языка поанализировать,Nashev,null, ,OPEN,,
33,Брать HTML-тексты по http и отображать их с форматированием,Nashev,null, ,OPEN,И уметь брать тексты по URL как с адресной строки, так и из адресов, найденных в тексте.

И уметь игнорировать/понимать разметку HTML. Уметь игнорировать меню, рекламу и прочую обвеску текстов на страницах.

И уметь отображать форматированные тексты с HTML-разметкой (кстати, это может помочь решить #2),
32,Отдельные сети знаний и их сравнение/объединение/разделение/совместное использование,Nashev, , ,OPEN,Отдельные в рамках одного мозга, для разных контекстов или источников, отдельные в рамках разных мозгов/проектов, для разных исследователей/компьютеров/наборов источников.

При этом даже объединив, нужно не терять связи с источниками (или терять их лишь целенаправленно, если захочется) и иметь возможность как-то разделить, что откуда известно.

При сравнении - видеть, что вот это - общее, это - лишь там, это - противоречит.

При разделении - по источникам, по понятиям, по точкам зрения, или ещё как.. Общие части сдублировать или выделить в совместно используемую "библиотеку" более базовых знаний.

Для совместного использования - нужно различать знания по принадлежности, то есть уметь ссылаться из одного мозга в другой (учесть в #24 и #6).,
31,Фоновый режим работы с чтением новостей с сайта и уведомлениям о новых фактах по запросу,Nashev,null, ,OPEN,Типа поискового краулера или по rss,
30,Распознаватели и типы элементов знаний - как плагины,Nashev,null, ,OPEN,Компилированные или вовсе скриптовые... Или отдельные утилиты (#20),
29,Кластерный анализ источников,Nashev,null, ,OPEN,Показывать несколько об одном и том же говорят разные источники. Например, по количеству общих и собственных понятий... ,
28,Запросы на естественном языке, NLP, Rule Based Queries,Nashev,null, ,OPEN,Понять, что за хрень и как её готовить. Полезна ли? ,
27,В качестве источника знаний иметь ещё и ручной ввод ,Nashev,null, ,OPEN,К нему относить все элементы знаний, добавляемые через GUI. 

Возможно, к нему же относить всё подтверждённое пользователем - типа, выявленные им из текста знания. ,
26,Частотный анализ словосочетаний,Nashev,null, ,OPEN,Возможно, на анализе повышенного разнообразия мест применения слов и знаков в тексте получится служебные слова и знаки отличить от слов, несущих понятия. 

Выделить устойчивые словосочетания #10. ,
25,Понятия выделять, хотябы вручную ,Nashev,null, ,OPEN,Кроме слов, нужны понятия.
Синонимы - это слова, связанные с одним понятием.
Омонимы - это понятия, связанные с одним словом. 

Понятия должны иметь тесную связь с источниками, напрямую, а не через слова - чтобы можно было понимать, где о каком понятии речь шла, и различать тексты о разных понятиях. 

А ещё чтобы утверждения из разных источников можно было различить, и сверять источники через них, оценивать достоверность... ,
24,Выгрузка элементов знания из памяти и их адресация в таких условиях,Nashev,null, ,OPEN,Наверно стоит, делая #6, в памяти не хранить имена вместо указателей на выгруженные элементы, а подменять указатели указателями на знания-заглушки, которые будут помнить, где искать на диске сам элемент знания.

Соответственно, при обращении к элементу - иметь ввиду, что он может быть выгружен, и если правильно обратиться к его содержимому, оно будет подгружено.

То есть, при варианте с заглушками, адрес элемента может поменяться с адреса заглушки на адрес самого элемента. То есть, при обращении по указателю link надо делать что-то типа link := link.actualize;, а при выгрузке элемента из памяти - перебирать все линки по списку ссылающихся, и подменять их на оставляемую вместо элемента заглушку.

С другой стороны, наверно проще иметь у элемента знания отделяемое содержимое, а при выгрузке - в качестве заглушки оставлять его самого же, но без содержимого. То есть выгружать лишь внутренности. Или иметь их отделяемыми, а сам элемент знания - лишь пустой обёрткой вокруг них, с механизмом загрузки-выгрузки.

К внутренностям относятся связи элемента и всё что ещё ему там надо, к обёртке - идентификатор и имя класса внутренностей.

То есть, выгруженный элемент знаний не знает, кто на него ссылается?... хм. Наверно, нужно чтобы выгруженный - он помнил список лишь тех ссылающихся, которые есть в памяти, и нужны кому-то ещё, а загруженный - будет помнить полный список, находя или создавая незагруженными для его работы адресуемые элементы, нужные ему самому.,
23,TWordWasCapitalizedFact делать не на TModifiedWord,Nashev,null, ,OPEN,А лишь на основании прямого обнаружения в словаре слова в ином регистре.

Сам TModifiedWord вроде бы вовсе ненужен получается.. Вместо него нужна "основная форма слова" (#47, "[лемма](https://ru.wikipedia.org/wiki/%D0%9B%D0%B5%D0%BC%D0%BC%D0%B0_(%D0%B7%D0%BD%D0%B0%D1%87%D0%B5%D0%BD%D0%B8%D1%8F))" или "[стемма](https://ru.wikipedia.org/wiki/%D1%F2%E5%EC%EC%E8%ED%E3)"), которую и связи с которой надо определять как-нибудь потом, отдельно...,
22,Из текста в браузер знаний,Nashev,null, ,OPEN,Чтоб в тексте встать на слово - и браузеры знаний на него спозиционировать.,
21,TextBrain — это ж алфавитный указатель, Index,Nashev,null, ,OPEN,То что у меня на текущий момент получилось - это фактически он и есть. Морфологию вот только подключить...

И далее - самое интересное - понять, чем оно круче алфавитного указателя. И перепозиционировать сделанное как программу для создания указателя ;)

Осмыслить эту мысль надо.,
20,Многопоточность, многопроцессность, расчёты отдельно от GUI, утилиты, прогресс/отмена,Nashev,null, ,OPEN,На базе файлового хранилища #6 можно думать об одновременной работе с одним массивом знаний сразу нескольких компьютеров. 

Может получиться как вычислительный кластер, так и многопользовательская система. 

(У других это называется [мультиагентная](http://www.magenta-technology.ru/ru/technology/overview/different/), где агент - это то, что у меня названо "распознаватель", но [говорят](http://www.magenta-technology.ru/ru/technology/why/benefits/) что очень полезно уметь работать и с кучей "агентов"/распознавателей в одном потоке).,
19,Браузер понятий типа mindmap,Nashev,null, ,OPEN,Чтобы существительное раскрывалось на используемые с ним глаголы и эпитеты, те в свою очередь раскрывались по своим связям и т. д. ,
18,Описать структуру классов и подходы к их использованию (в wiki или исходниках),Nashev,null, ,OPEN,Если в исходниках - то используя [FPDoc](http://www.freepascal.org/docs-html/fpdoc/fpdocse2.html) и http://wiki.freepascal.org/FPDoc_Editor/ru,
16,Браузер знаний соорудить, графический,Nashev,null, ,OPEN,В дополнение к браузеру знаний колоночному #15:

Для отображения всех знаний или, что реалистичнее, ближайшего подмножества - на нём можно будет не только дочки дочек и родителей родителей видеть, но и, например, соседей текущего элемента - типа других родителей дочек и других дочек родителей, и их связи, если они есть. Но тут не факт что получится удобно автоматически размещать элементы графа на экране.,
15,Браузер знаний колоночный,Nashev,null, ,OPEN,Несколько колонок, центральная - текущий элемент, в ней описание и сведения всякие. Слева от центральной - колонка со списком ближайших предков текущего элемента, то есть элементы, непосредственно ссылающиеся на текущий элемент, справа - аналогичный список ближайших потомков. Слава и справа от них - предки и потомки второго уровня, возможно лишь для текущего элемента в ближайшем списке, а можно и все вместе. Или с переключателем на этот счёт... Или всех выделенных, а не выделены по умолчанию никакие.

Двойным щелчком по элементу в любом из этих списков - перекинуть элемент в центр, и смотреть с его точки зрения.

Крайние колонки - просмотр объединённых списков связанных элементов знаний на несколько уровней сразу, с регулятором количества.

С фильтрацией по типу #9 и ещё чему угодно, с расcкраской, с пояснениями, статистикой, всплывалками и синхронизацией с текстом #14 и его картой #8.

Возможно, получится и в виде графа браузер знаний соорудить, графический (см #16 ). ,
13,Изучать "конкурентов",Nashev,null, ,OPEN,Смотреть что уже есть и тырить идеи ),
12,Автоматизированный перевод,Nashev,null, ,OPEN,По мотивам http://habrahabr.ru/company/abbyy/blog/208902/
Если у меня получится показывать понятия и утверждения о них, возможно будет удобно на основе этого перевод текстов делать.

Соответственно, нужны знания об отношении к языку и разноязычные синонимы.

так же для этой задачи полезны 
* "базы Translation Memory — базы памяти переводов, которые содержат ранее переведенные сегменты текста (словосочетания и предложения). Они создаются и пополняются на основе пар параллельных текстов. 
* Другой важный ресурс — глоссарии, которые содержат термины и понятия, принятые в той или иной компании либо утвержденные для определенной группы проектов."
(см про Lingvo.Pro - http://habrahabr.ru/company/abbyy/blog/202300/),
11,Самообучение, Rule Based Analytic,Nashev,null, ,OPEN,Изначально была идея попробовать не только находить предопределённые типы элементов знаний (см #9), но и  самообучение организовать: чтобы какой-нибудь минимальный комплект простых абстрактных детекторов, работая рекурсивно, образовал прорывной системный эффект, начав распознавать что-то хитрое и сложное. ,
10,Словосочетания (N-граммы),Nashev,null, ,OPEN,Надо распознавать устойчивые словосочетания. Это такие словосочетания ([N-граммы](https://ru.wikipedia.org/wiki/N-%D0%B3%D1%80%D0%B0%D0%BC%D0%BC)), которые встречаются много раз - сопоставимо с количеством упоминаний составляющих его слов.

Надо отличать склоняемые от не склоняемых или частично склоняемых. Видимо, надо искать их и на уровне базовых словоформ (#47), и на уровне используемых.,
9,Выписать виды элементов знания,Nashev,null, ,OPEN,Возможно, надо как-то разделять понятия "мы знаем что-то про текст" и "мы знаем что-то про то, что описано в тексте". Не факт, что это возможно. Достаточно ли опираться на то, что "элемент знания" опирается непосредственно на "элемент исходного текста"? Или более глубокие элементы тоже бывают сугубо про текст? Есть ли элементы, которые то так то эдак? Надо б выписать какие элементы знания есть и какие могут быть.

Уже есть:
Слова исходного текста; Используемые словоформы в разных регистрах; Используемые словоформы без регистра. 
Еще нет: Слова в основной форме, базовые для используемых словоформ (#47); Синонимы (#48); морфологическая информация (род, число, падеж, склонение и т. п. характеристики) словоформ. Надо придумать, что делать с омонимами. Видимо, различать на следующем уровне, над словоформами. На основании смыслов, связей, контекста.   

Еще надо бы, по структуре текста:
Главы, разделы, подразделы, параграфы, предложения, словосочетания #10, группы слов (оборот, предложная группа), выделения всякие типа курсива... 
Согласованные слова из предложений. Опоры местоимений (анафора)... 

Распознавать парность скобок, запятых, кавычек и т.п. элементов

Извлечённые факты, такие как:
Основные понятия текста 
Основные утверждения текста

Например то, что упоминается один раз - это то, что текст утверждает нового. То, что упоминается много раз - это то, о чём текст. Иначе - значит в тексте есть лишние повторы утверждений. (это уже части #46)

,
8,Карта текста,Nashev,null, ,OPEN,Панелька, на которой в пределах экрана врисован весь массив текста и разным образом отмечены места, отображаемые на экране и места, связанные с нужным в данный момент понятием или ещё чем. 

Как в BeyondCompare и прочих сравнивалках есть двойная полоса с отметками о положении отличий.

Возможно, эта панелька должна выполнять и роль полосы прокрутки - как в хроме, где результаты поиска текста на странице рисуются не только выделением в тексте  (см #2), но и отметками на полосе прокрутки.,
7,Нужно у знаний хранить признак продуктивности,Nashev,null, ,OPEN,Это может быть таймкод последнего обращения, или счётчик бесполезных обращений, или счётчик полезных обращений, или что-то типа того. 

Чтобы знать, что допустимо "забыть" из оперативки при подгрузке нового нужного (см #6), а что не стоит.

Cчётчик бесполезных обращений кажется пока наиболее перспективным, если его обнулять или ополовинивать при полезных.,
6,Работа с памятью / диском,Nashev,null, ,OPEN,Читать файл по частям

Хранить знания мозга по частям, на диске. В человекочитаемом формате и с возможностью версионирования с помощью git (см #5 про редактирование и undo/redo)

Не загружать всегда все знания в оперативку, понять их структуру и решить, как побить на файлы так, чтобы из этих файлов каждый раз при запросах и работе брать лишь нужный кусочек.

Или даже сделать кеширование - то есть всё же держать в памяти по максимуму, но при нехватке оперативки скидывать не нужное на диск из памяти, и при запросе вовремя брать с диска то, что нужно для его выполнения.

Для этого нужно архитектуру сделать такой, чтобы детекторы могли запросить нужные для своей работы знания у хранилища, не перебирая самостоятельно всё подряд - то есть механизм отбора должен быть не у детектора, а у хранилища и позволять ему  самому находить на диске нужные части.

Нужно определить, какие критерии отбора можно сделать.

Мысль: по аналогии с мозгом можно попробовать пойти
* Действовать по ассоциации: стараться выращивать у элемента знания "дендриты" и "аксоны" с их синапсами, касающимися других конкретных элементов знания, то есть **знаниям надо помнить уникальный индекс других знаний в общем массиве знаний, и обращаться к ним по индексу, а не указателю**.
* А для выращивания - активные каким-то образом элементы знаний могут тянуться в определённую область, где сейчас что-то происходит из сенсорного потока, почему-то касающееся их. **То есть, новые связи с новым элементом из сенсорного потока будут делаться не для всех старых элементов мозга, а для каким-то образом избранной их части (эмоции их активировали или ещё как?..)** 
* Далее, разные области мозга отвечают за разные виды информации - зрительная, там, моторная области коры и т.п... Соответственно, можно пробовать расти в нужную область, то есть **возможно нужно уметь отбирать элементы знания ещё и по типу знания, по классу KnowledgeItem (см #9).**
* Кратковременная память есть, на 5±2 элемента, которая помнит недавние события. Возможно, новые знания имеет смысл изначально искать лишь среди них? **Иметь буфер недавно обрабатывавшихся или недавно добавленных знаний.** (http://habrahabr.ru/post/148461/ чуток в тему, как компактный обзор и инфографика)
* Работа подсознания есть, когда загружаешь мозг чем-то, отвлекаешься, а котелок варит, и наступает инсайт. То есть, **в общем массиве знаний можно искать что-то фоновым краулером, который не спеша будет планомерно прочёсывать всё подряд, начиная с какой-то тоже близкой области?**
* Вспомненное, активированное - тоже начинает влиять на то, что придумывается головой. То ли через кратковременную память, то-ли через ещё что-то.. **Можно недавно подгруженные с диска элементы знаний тоже некоторое время прочёсывать в поисках новых знаний, и выгружать лишь те, которые к моменту потребности в оперативке не продуцировали новых знаний** (Отсюда, кстати, вывод #7 - нужно у знаний хранить признак продуктивности - таймкод последнего обращения ли, счётчик бесполезных обращений ли, счётчик полезных обращений или что-то типа того. Чтобы знать, что "забыть" из оперативки, а что не стоит).


Индексом элемента знания может быть путь на диске, и состоять он должен из типа и имени. Имя может быть тоже составным, для защиты от переполнения папок. Числовым, строковым - не важно, главное - стабильным и уникальным, допустимым для имени файла и, по возможности, человекочитаемым. 

Элемент знания - отдельный файл или часть в общем файле.

Как при таком подходе представить слова и иные части исходного текста, если их много и они с привязкой к месту в нём, а он потенциально редактируемый? Возможно, стоит отказаться от адресации и строить лишь цепочки со связями типа предыдущее и следующее слово. Индекс им можно  делать как хеш конкатенации индекса предыдущего слова и самого слова. С приписыванием случайной фигни в случае коллизии. Так хеш будет накопительным что позволит ему реже повторяться при встрече одинаковых слов. И он не будет последовательным, как в случае использования счетчика, и не будет смущать при перестановках в результате редактирования текста. ,
5,Развить систему в сторону динамического формирования текста (Книгописательство!),Nashev,null, ,OPEN,В дополнение к #4 (Анализ текста)

* Пересогласование фраз при замене подлежащего, сказуемого и т.п., вообще при изменении любого слова в структуре предложения.
 * Для этого можно отображать все словоформы слова в контекстном меню

* Перемещение абзацев по структуре текста.

* Пополнение "мозга" дополнительными "знаниями", которые отсутствуют в исходном тексте - и отображение таких знаний особым образом, чтоб было видно, что в тексте их нигде нет. Автоматическое формирование формулировок из этих знаний и удобное добавление их в текст.

* Онлайн-изменение знаний в мозге при модификации текста

* Undo/Redo неограниченной глубины.
 * История изменений. Версионность изменений. (Интеграция с git? #44)
 * Хранение знаний мозга в таком виде, чтобы дифы в истории были достаточно наглядны. (см. #6)
 * Подхват изменений хранимого варианта при смене ветки репозитория или ручной правке файлов
,
4,Анализ текста - как сбор его характеристик/метрик, так и вычисление выводов из него.,Nashev,null, ,OPEN,Развить систему в сторону статического анализа текстов:
* [стемминг](https://ru.wikipedia.org/wiki/%D1%F2%E5%EC%EC%E8%ED%E3) (#47), морфологический анализ, грамматический анализ
  * для всех слов уметь выписывать их словоформы, с отображением частотности употребления
  * для выделенного предложения и слова уметь отображать структуру предложения (подлежащее, сказуемое, обороты) и связи слова в предложении - какие слова с текущим согласованы по числу, роду, падежу и т.п. (см. #2)
  * извлекать перечни понятий, с отображением частотности употребления
    * для понятия уметь выписывать их свойства - какие они и что делают, и что с ними делают (прилагательные и глаголы), с отображением частотности употребления. 
* Частотность употребления показывать подсветкой мест в тексте и в карте текста (иметь карту текста! см #8)
* Уметь связывать синонимы (#48), и при желании, не отличать их друг от друга при анализе. Типа галочки в свойствах слова в выдаче отчёта по нему - "включая связи синонимов".
* Уметь определять или хотя бы задавать назначение абзаца для понятия - определение, уточнение, изменение, использование.
* Уметь определять структуру текста - главы, разделы, параграфы, абзацы, предложения. Их вложенность, их зависимость по понятиям - типа, тут введено а тут используется или поясняется. 

Будут средства всё это смотреть - получится #46.

Иметь средства просмотра основных вещей непосредственно у текста, и средства генерирования отчётов по отдельным аспектам, которые на самом тексте не возможно показать.

Возможно, надо как-то разделять понятия "мы знаем что-то про текст" и "мы знаем что-то про то, что описано в тексте". Не факт, что это возможно. Достаточно ли опираться на то, что "элемент знания" опирается непосредственно на "элемент исходного текста"? Или более глубокие элементы тоже бывают сугубо про текст? Есть ли элементы, которые то так то эдак? Надо б выписать какие элементы знания есть и какие могут быть (см. #9). 

Для всех результатов иметь экспорт, для включения в публикации на тему анализа.

(см. далее #5: Развить систему в сторону динамического формирования текста) ,
3,Использовать шаблоны классов для организации списков и итераторов ,Nashev,null, ,OPEN,Чтобы меньше дублировать типовой код,
2,Рисовать значки поверх текста,Nashev,null, ,OPEN,Выделять слова, части слов, связи слов и т. п. 
Для определения координат букв - сообщения есть, на http://last12.narod.ru/delphi_memrihonline.htm описаны. ,
1,Выбор кодировки после выбора файла, с просмотром содержимого,Nashev,null, ,OPEN,Типа как мастер импорта теста в экселе - показать начало теста, дать сменить декодер, еще что-нибудь поднастроить... ,
17,Локализовать, на русский, при английских исходниках,Nashev,null, ,CLOSED,,
14,Отображать сам загруженный/редактируемый текст,Nashev,null, ,CLOSED,Прежде, чем рисовать поверх него (см. #2) и рисовать его карту (см. #8),
